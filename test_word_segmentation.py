#!/usr/bin/env python3
"""
Test script Ä‘á»ƒ kiá»ƒm tra word segmentation vÃ  embedding vá»›i cÃ¢u tiáº¿ng Viá»‡t
"""

import os
import sys
import numpy as np
import onnxruntime as ort
from transformers import AutoTokenizer
import logging

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Test cÃ¢u tiáº¿ng Viá»‡t
test_sentence = "HÃ´m nay thá»i tiáº¿t ráº¥t Ä‘áº¹p, tÃ´i Ä‘i dáº¡o trong cÃ´ng viÃªn vÃ  gáº·p nhiá»u ngÆ°á»i báº¡n."

def test_word_segmentation():
    """Test Vietnamese word segmentation"""
    try:
        from pyvi.ViTokenizer import tokenize as vi_tokenize
        logger.info("âœ… PyVi available for word segmentation")
        
        # Test segmentation
        segmented = vi_tokenize(test_sentence)
        logger.info(f"ğŸ“ Original: {test_sentence}")
        logger.info(f"ğŸ”¤ Segmented: {segmented}")
        
        return segmented
    except ImportError:
        logger.warning("âš ï¸ PyVi not available, skipping word segmentation")
        return test_sentence
    except Exception as e:
        logger.error(f"âŒ Word segmentation error: {e}")
        return test_sentence

def test_onnx_embedding():
    """Test ONNX embedding generation"""
    try:
        # Check if model files exist
        model_path = "/opt/spark/work-dir/model/embedding"
        if not os.path.exists(model_path):
            logger.error(f"âŒ Model path not found: {model_path}")
            return None
        
        # List model files
        files = os.listdir(model_path)
        logger.info(f"ğŸ“ Model files: {files}")
        
        # Load ONNX model
        onnx_path = os.path.join(model_path, "model.onnx")
        if not os.path.exists(onnx_path):
            logger.error(f"âŒ ONNX model not found: {onnx_path}")
            return None
        
        logger.info("ğŸ”„ Loading ONNX model...")
        session = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])
        logger.info("âœ… ONNX model loaded successfully")
        
        # Load tokenizer from original model
        logger.info("ğŸ”„ Loading tokenizer...")
        try:
            tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-base")
            logger.info("âœ… Tokenizer loaded successfully from vinai/phobert-base")
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to load from vinai/phobert-base: {e}")
            # Try loading from local path
            tokenizer = AutoTokenizer.from_pretrained(model_path)
            logger.info("âœ… Tokenizer loaded successfully from local path")
        
        # Test with Vietnamese sentence
        logger.info(f"ğŸ“ Testing with: {test_sentence}")
        
        # Tokenize
        inputs = tokenizer(
            test_sentence,
            padding=True,
            truncation=True,
            max_length=512,
            return_tensors="np"
        )
        
        logger.info(f"ğŸ”¤ Tokenized input shape: {inputs['input_ids'].shape}")
        
        # Run inference
        input_ids = inputs["input_ids"].astype(np.int64)
        attention_mask = inputs["attention_mask"].astype(np.int64)
        
        logger.info("ğŸ”„ Running ONNX inference...")
        outputs = session.run(
            None,
            {
                "input_ids": input_ids,
                "attention_mask": attention_mask
            }
        )
        
        # Extract embeddings
        embeddings = outputs[0]  # Shape: (batch_size, seq_len, hidden_size)
        logger.info(f"ğŸ“Š Embeddings shape: {embeddings.shape}")
        
        # Pool embeddings (mean pooling)
        attention_mask_expanded = attention_mask[:, :, None]
        pooled_embeddings = np.sum(embeddings * attention_mask_expanded, axis=1) / np.sum(attention_mask_expanded, axis=1)
        
        logger.info(f"ğŸ“Š Pooled embeddings shape: {pooled_embeddings.shape}")
        logger.info(f"ğŸ“Š Embedding dimension: {pooled_embeddings.shape[1]}")
        logger.info(f"ğŸ“Š First 5 values: {pooled_embeddings[0][:5]}")
        
        return pooled_embeddings
        
    except Exception as e:
        logger.error(f"âŒ ONNX embedding error: {e}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """Main test function"""
    logger.info("ğŸš€ Starting Vietnamese word segmentation and embedding test")
    
    # Test word segmentation
    logger.info("\n" + "="*50)
    logger.info("1. Testing Vietnamese Word Segmentation")
    logger.info("="*50)
    segmented_text = test_word_segmentation()
    
    # Test ONNX embedding
    logger.info("\n" + "="*50)
    logger.info("2. Testing ONNX Embedding Generation")
    logger.info("="*50)
    embeddings = test_onnx_embedding()
    
    if embeddings is not None:
        logger.info("âœ… Test completed successfully!")
        logger.info(f"ğŸ“Š Final embedding shape: {embeddings.shape}")
    else:
        logger.error("âŒ Test failed!")

if __name__ == "__main__":
    main()
